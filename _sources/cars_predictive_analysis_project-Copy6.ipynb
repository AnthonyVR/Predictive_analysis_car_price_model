{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8c8316",
   "metadata": {},
   "source": [
    "# 4. Machine learning fundamental methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1dfc8",
   "metadata": {},
   "source": [
    "**To start using machine learning algorithms, we first have to feature scale the data, otherwise some features may have a much bigger impact on the result than we want.**\n",
    "\n",
    "**To do this, I chose for standardization, this is because it's better suited for outliers and there are quite some 'extreme' values. For example, the mpg values for the BMW i3 models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b732934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#price should not be standardized as this is the target feature\n",
    "df_scaled = df\n",
    "df_scaled[['year', 'mileage', 'tax', 'mpg', 'engineSize']] = StandardScaler().fit_transform(df[['year', 'mileage', 'tax', 'mpg', 'engineSize']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "955a255a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>-0.051134</td>\n",
       "      <td>12500</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>0.490676</td>\n",
       "      <td>-0.020329</td>\n",
       "      <td>-0.522268</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A6</td>\n",
       "      <td>-0.523558</td>\n",
       "      <td>16500</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>0.636923</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>-1.400694</td>\n",
       "      <td>0.502057</td>\n",
       "      <td>0.549071</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1</td>\n",
       "      <td>-0.523558</td>\n",
       "      <td>11000</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0.337156</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>-1.400694</td>\n",
       "      <td>-0.020329</td>\n",
       "      <td>-0.522268</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4</td>\n",
       "      <td>-0.051134</td>\n",
       "      <td>16800</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>0.145807</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>0.411869</td>\n",
       "      <td>0.686079</td>\n",
       "      <td>0.013401</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3</td>\n",
       "      <td>0.893714</td>\n",
       "      <td>17300</td>\n",
       "      <td>Manual</td>\n",
       "      <td>-1.001808</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>0.411869</td>\n",
       "      <td>-0.364628</td>\n",
       "      <td>-1.236494</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model      year  price transmission   mileage fuelType       tax       mpg  \\\n",
       "0    A1 -0.051134  12500       Manual  0.048715   Petrol  0.490676 -0.020329   \n",
       "1    A6 -0.523558  16500    Automatic  0.636923   Diesel -1.400694  0.502057   \n",
       "2    A1 -0.523558  11000       Manual  0.337156   Petrol -1.400694 -0.020329   \n",
       "3    A4 -0.051134  16800    Automatic  0.145807   Diesel  0.411869  0.686079   \n",
       "4    A3  0.893714  17300       Manual -1.001808   Petrol  0.411869 -0.364628   \n",
       "\n",
       "   engineSize  make  \n",
       "0   -0.522268  audi  \n",
       "1    0.549071  audi  \n",
       "2   -0.522268  audi  \n",
       "3    0.013401  audi  \n",
       "4   -1.236494  audi  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1b40bf",
   "metadata": {},
   "source": [
    "**Looks good.** \n",
    "\n",
    "**Now we can extract the numeric columns and split the dataset into a train- and testset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dde1fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_num = df_scaled.drop(['model','make', 'transmission', 'fuelType'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09978d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df_scaled_num, test_size=0.2)\n",
    "\n",
    "train = train_set.drop(\"price\", axis=1)\n",
    "train_labels = train_set[\"price\"]\n",
    "\n",
    "test = test_set.drop(\"price\", axis=1)\n",
    "test_labels = test_set[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd25634",
   "metadata": {},
   "source": [
    "**Done, ready to test some ML algorithms nows.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a8567",
   "metadata": {},
   "source": [
    "## 4.1 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2bb1d",
   "metadata": {},
   "source": [
    "**I chose for Linear regression as the first algorithm because from the exploration of the data we saw that there is quite some correlation. Furthermore, linear regression is a simple algorithm yet it can be very powerful, and overfitting won't be a problem with this method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dab2ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d86db4",
   "metadata": {},
   "source": [
    "**To check how well the model has done, I used the Root Mean Square Error, as this is a simple and reliable method for evaluation linear regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bf35aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5395.422643040363"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "car_predictions = lin_reg.predict(train)\n",
    "lin_mse = mean_squared_error(train_labels, car_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b517e539",
   "metadata": {},
   "source": [
    "**Not too great, but it's something. Let's implement a way to be able to check the outcome more in detail and compare with other algorithms. Cross-validation would be a good choice here. By using different samples of the dataset to train the model on different iterations, we will have a more reliable outcome of the quality of the model.**\n",
    "\n",
    "**First let's use a function which we can reuse to compare models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e289e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a82369a",
   "metadata": {},
   "source": [
    "**Now we can use cross-validation to get the scores.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39b94997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [5445.16111606 5410.45754548 5430.37882098 5370.35981378 5293.53615971\n",
      " 5401.13000828 5477.67028917 5472.29654872 5457.31826448 5219.59351925]\n",
      "Mean: 5397.790208590681\n",
      "Standard deviation: 78.94849017417117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "lin_scores = cross_val_score(lin_reg, train, train_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af097db1",
   "metadata": {},
   "source": [
    "**A mean score of 5397 with a std of 78.9, not bad.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda1937",
   "metadata": {},
   "source": [
    "## 4.2 Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e165ba94",
   "metadata": {},
   "source": [
    "**As there are multiple correlated features, a decision tree might be a good way to predict the price as well, let's try.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e60a7e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeb826b",
   "metadata": {},
   "source": [
    "**Calculating the RMSE for this model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0058e3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493.0212997677965"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "car_predictions = tree_reg.predict(train)\n",
    "tree_mse = mean_squared_error(train_labels, car_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a919a",
   "metadata": {},
   "source": [
    "**This is a very good score, but a decision tree is prone to overfitting, so using cross-validation is important here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a2c38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_reg, train, train_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5d1338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [4485.01800666 4469.08315329 4472.93283517 4554.87195759 4643.74124483\n",
      " 4366.58783022 4144.86588929 4218.71250221 4323.31381603 4456.51067654]\n",
      "Mean: 4413.563791184277\n",
      "Standard deviation: 143.8833788543146\n"
     ]
    }
   ],
   "source": [
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49688495",
   "metadata": {},
   "source": [
    "**A mean score of 4413 and an std of 143.8, not bad either but linear regression scored better.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85fcbea",
   "metadata": {},
   "source": [
    "## 4.3. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56426364",
   "metadata": {},
   "source": [
    "**Now let's try random forest, this is a more complicated model than a decision tree and often gives better results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf9ceece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6f09de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [4121.68551044 3825.28314621 4040.04856203 3985.48771427 3709.62626473\n",
      " 4026.75309949 3971.12959352 3869.77501584 3992.83323101 3810.98219204]\n",
      "Mean: 3935.360432958071\n",
      "Standard deviation: 119.98703078758932\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(forest_reg, train, train_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e6c84",
   "metadata": {},
   "source": [
    "**Lower scores than decision tree, but better std. Linear regression still scored best.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
