{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7fec070",
   "metadata": {},
   "source": [
    "# 5. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3026ce02",
   "metadata": {},
   "source": [
    "**I know this is beyond the scope of the course, but I've been learning about neural networks out of interest lately and I wanted to try building one to test myself on this subject. Before I started, I realized that this model would probably perform worse than the more fundamental methods, but that was not the goal. The goal was to learn something and have fun, which I most certainly did.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87aeff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 08:48:08.662186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-25 08:48:08.662263: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38a791",
   "metadata": {},
   "source": [
    "Some minor errors and warnings, nothing to worry about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d0256",
   "metadata": {},
   "source": [
    "**Let's first build a model using Keras library. I have a laptop without a gpu, so my neural network will have to train on my cpu. Also I don't have many days left to train my model so I will definetely have to make some sacrifices on performance.**\n",
    "\n",
    "**First of all I made the choice to use only 3 layers (1 hidden layer), otherwise training would take much to long.**\n",
    "\n",
    "**For my activation functions on the first 2 layers, I chose for ReLU, as it is a fast yet quite reliable choice for regression. as my third layer only has 1 neuron with a single value, I did not need an activation function for that.**\n",
    "\n",
    "**With my optimizer and loss functions, I didn't go to fancy either, I mainly needed a fast and simple functions. Furthermore, mse is often a good choice for 'simple' regression tasks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9a307cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train.keys())]),\n",
    "        layers.Dense(64, activation=tf.nn.relu),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    \n",
    "    model.compile(loss='mse',\n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773b5d11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7359/1335155156.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'build_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be3b2e",
   "metadata": {},
   "source": [
    "**(I accidentally tried running this cell again after training my model but I didn't want to run everything over again so that it why it now says build_model not found, before this worked ofcourse.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c931b162",
   "metadata": {},
   "source": [
    "**Let's have a look at our model now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4c63447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                384       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,609\n",
      "Trainable params: 4,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e35e25",
   "metadata": {},
   "source": [
    "**Looks good, now let's test if our model is set up correctly by testing it on a small subset of the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50334afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05787908],\n",
       "       [ 0.18334435],\n",
       "       [ 0.37936437],\n",
       "       [ 0.2206813 ],\n",
       "       [ 0.10483198],\n",
       "       [-0.07229923],\n",
       "       [-0.0250116 ],\n",
       "       [ 0.1843274 ],\n",
       "       [ 0.08441111],\n",
       "       [ 0.20493421]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = train[:10]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01783194",
   "metadata": {},
   "source": [
    "**Everything seems to work fine, let's train the model now.**\n",
    "\n",
    "**As this will take hours, I used a printDot() function to print a dot on every iteration of training, to make sure the training is still busy.**\n",
    "\n",
    "**Then I started training the model with 1000 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28d54964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: pr \n",
    "              int('')\n",
    "        print('.', end='')\n",
    "            \n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(train, train_labels, epochs=EPOCHS, validation_split = 0.2, verbose = 0, callbacks=[PrintDot()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4daf6ce",
   "metadata": {},
   "source": [
    "**Done, this took about 3 hours to train already, so unfortunately I won't have the time to tweak a lot with my loss-, activation-, and optimizer functions. Let's hold on to the basics.**\n",
    "\n",
    "**Let's now check the results of our last training iterations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d3e4717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>15706116.0</td>\n",
       "      <td>2616.107178</td>\n",
       "      <td>15706116.0</td>\n",
       "      <td>16305415.0</td>\n",
       "      <td>2645.844971</td>\n",
       "      <td>16305415.0</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>15697392.0</td>\n",
       "      <td>2615.675049</td>\n",
       "      <td>15697392.0</td>\n",
       "      <td>16330255.0</td>\n",
       "      <td>2640.858887</td>\n",
       "      <td>16330255.0</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>15704668.0</td>\n",
       "      <td>2615.661133</td>\n",
       "      <td>15704668.0</td>\n",
       "      <td>16375983.0</td>\n",
       "      <td>2636.772461</td>\n",
       "      <td>16375983.0</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>15655734.0</td>\n",
       "      <td>2613.237061</td>\n",
       "      <td>15655734.0</td>\n",
       "      <td>16355840.0</td>\n",
       "      <td>2653.677979</td>\n",
       "      <td>16355840.0</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>15655700.0</td>\n",
       "      <td>2614.472900</td>\n",
       "      <td>15655700.0</td>\n",
       "      <td>16400591.0</td>\n",
       "      <td>2652.961670</td>\n",
       "      <td>16400591.0</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss          mae         mse    val_loss      val_mae     val_mse  \\\n",
       "995  15706116.0  2616.107178  15706116.0  16305415.0  2645.844971  16305415.0   \n",
       "996  15697392.0  2615.675049  15697392.0  16330255.0  2640.858887  16330255.0   \n",
       "997  15704668.0  2615.661133  15704668.0  16375983.0  2636.772461  16375983.0   \n",
       "998  15655734.0  2613.237061  15655734.0  16355840.0  2653.677979  16355840.0   \n",
       "999  15655700.0  2614.472900  15655700.0  16400591.0  2652.961670  16400591.0   \n",
       "\n",
       "     epoch  \n",
       "995    995  \n",
       "996    996  \n",
       "997    997  \n",
       "998    998  \n",
       "999    999  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a8167",
   "metadata": {},
   "source": [
    "**To compare these results with our other predictive models, I decided to calcultate the rmse from the mse column, by taking the square root.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae77d4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>252111808.0</td>\n",
       "      <td>12809.167969</td>\n",
       "      <td>252111808.0</td>\n",
       "      <td>43941684.0</td>\n",
       "      <td>4920.054688</td>\n",
       "      <td>43941684.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15878.029097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33763576.0</td>\n",
       "      <td>4027.907959</td>\n",
       "      <td>33763576.0</td>\n",
       "      <td>26813236.0</td>\n",
       "      <td>3530.665283</td>\n",
       "      <td>26813236.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5810.643338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25565760.0</td>\n",
       "      <td>3350.553711</td>\n",
       "      <td>25565760.0</td>\n",
       "      <td>23330678.0</td>\n",
       "      <td>3242.599609</td>\n",
       "      <td>23330678.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5056.259487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23724400.0</td>\n",
       "      <td>3195.875732</td>\n",
       "      <td>23724400.0</td>\n",
       "      <td>22420352.0</td>\n",
       "      <td>3152.117676</td>\n",
       "      <td>22420352.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4870.769960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23093154.0</td>\n",
       "      <td>3147.664795</td>\n",
       "      <td>23093154.0</td>\n",
       "      <td>22037216.0</td>\n",
       "      <td>3134.419189</td>\n",
       "      <td>22037216.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4805.533685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>15706116.0</td>\n",
       "      <td>2616.107178</td>\n",
       "      <td>15706116.0</td>\n",
       "      <td>16305415.0</td>\n",
       "      <td>2645.844971</td>\n",
       "      <td>16305415.0</td>\n",
       "      <td>995</td>\n",
       "      <td>3963.094246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>15697392.0</td>\n",
       "      <td>2615.675049</td>\n",
       "      <td>15697392.0</td>\n",
       "      <td>16330255.0</td>\n",
       "      <td>2640.858887</td>\n",
       "      <td>16330255.0</td>\n",
       "      <td>996</td>\n",
       "      <td>3961.993438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>15704668.0</td>\n",
       "      <td>2615.661133</td>\n",
       "      <td>15704668.0</td>\n",
       "      <td>16375983.0</td>\n",
       "      <td>2636.772461</td>\n",
       "      <td>16375983.0</td>\n",
       "      <td>997</td>\n",
       "      <td>3962.911556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>15655734.0</td>\n",
       "      <td>2613.237061</td>\n",
       "      <td>15655734.0</td>\n",
       "      <td>16355840.0</td>\n",
       "      <td>2653.677979</td>\n",
       "      <td>16355840.0</td>\n",
       "      <td>998</td>\n",
       "      <td>3956.732743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>15655700.0</td>\n",
       "      <td>2614.472900</td>\n",
       "      <td>15655700.0</td>\n",
       "      <td>16400591.0</td>\n",
       "      <td>2652.961670</td>\n",
       "      <td>16400591.0</td>\n",
       "      <td>999</td>\n",
       "      <td>3956.728447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss           mae          mse    val_loss      val_mae  \\\n",
       "0    252111808.0  12809.167969  252111808.0  43941684.0  4920.054688   \n",
       "1     33763576.0   4027.907959   33763576.0  26813236.0  3530.665283   \n",
       "2     25565760.0   3350.553711   25565760.0  23330678.0  3242.599609   \n",
       "3     23724400.0   3195.875732   23724400.0  22420352.0  3152.117676   \n",
       "4     23093154.0   3147.664795   23093154.0  22037216.0  3134.419189   \n",
       "..           ...           ...          ...         ...          ...   \n",
       "995   15706116.0   2616.107178   15706116.0  16305415.0  2645.844971   \n",
       "996   15697392.0   2615.675049   15697392.0  16330255.0  2640.858887   \n",
       "997   15704668.0   2615.661133   15704668.0  16375983.0  2636.772461   \n",
       "998   15655734.0   2613.237061   15655734.0  16355840.0  2653.677979   \n",
       "999   15655700.0   2614.472900   15655700.0  16400591.0  2652.961670   \n",
       "\n",
       "        val_mse  epoch          rmse  \n",
       "0    43941684.0      0  15878.029097  \n",
       "1    26813236.0      1   5810.643338  \n",
       "2    23330678.0      2   5056.259487  \n",
       "3    22420352.0      3   4870.769960  \n",
       "4    22037216.0      4   4805.533685  \n",
       "..          ...    ...           ...  \n",
       "995  16305415.0    995   3963.094246  \n",
       "996  16330255.0    996   3961.993438  \n",
       "997  16375983.0    997   3962.911556  \n",
       "998  16355840.0    998   3956.732743  \n",
       "999  16400591.0    999   3956.728447  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist['rmse'] = hist['mse']**(1/2)\n",
    "hist.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbe724",
   "metadata": {},
   "source": [
    "**Not great, but understandable with only one hidden layer.**\n",
    "\n",
    "**Now let's use the EarlyStopping()function from Keras library to automatically find out at how many epochs the model doesn't improve anymore and can stop.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98c46fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................."
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='mse', patience=20)\n",
    "\n",
    "EPOCHS = 10000\n",
    "history = model.fit(train, train_labels, epochs=EPOCHS, \n",
    "                    validation_split=0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45b1dad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15711818.0</td>\n",
       "      <td>2614.414307</td>\n",
       "      <td>15711818.0</td>\n",
       "      <td>16939938.0</td>\n",
       "      <td>2730.013184</td>\n",
       "      <td>16939938.0</td>\n",
       "      <td>16</td>\n",
       "      <td>3963.813568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15723955.0</td>\n",
       "      <td>2615.282959</td>\n",
       "      <td>15723955.0</td>\n",
       "      <td>16436625.0</td>\n",
       "      <td>2639.060059</td>\n",
       "      <td>16436625.0</td>\n",
       "      <td>17</td>\n",
       "      <td>3965.344247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15701191.0</td>\n",
       "      <td>2613.296631</td>\n",
       "      <td>15701191.0</td>\n",
       "      <td>17102832.0</td>\n",
       "      <td>2737.846436</td>\n",
       "      <td>17102832.0</td>\n",
       "      <td>18</td>\n",
       "      <td>3962.472839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15690877.0</td>\n",
       "      <td>2615.295410</td>\n",
       "      <td>15690877.0</td>\n",
       "      <td>16380891.0</td>\n",
       "      <td>2633.541992</td>\n",
       "      <td>16380891.0</td>\n",
       "      <td>19</td>\n",
       "      <td>3961.171165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15656747.0</td>\n",
       "      <td>2613.933350</td>\n",
       "      <td>15656747.0</td>\n",
       "      <td>16787302.0</td>\n",
       "      <td>2642.258301</td>\n",
       "      <td>16787302.0</td>\n",
       "      <td>20</td>\n",
       "      <td>3956.860751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss          mae         mse    val_loss      val_mae     val_mse  \\\n",
       "16  15711818.0  2614.414307  15711818.0  16939938.0  2730.013184  16939938.0   \n",
       "17  15723955.0  2615.282959  15723955.0  16436625.0  2639.060059  16436625.0   \n",
       "18  15701191.0  2613.296631  15701191.0  17102832.0  2737.846436  17102832.0   \n",
       "19  15690877.0  2615.295410  15690877.0  16380891.0  2633.541992  16380891.0   \n",
       "20  15656747.0  2613.933350  15656747.0  16787302.0  2642.258301  16787302.0   \n",
       "\n",
       "    epoch         rmse  \n",
       "16     16  3963.813568  \n",
       "17     17  3965.344247  \n",
       "18     18  3962.472839  \n",
       "19     19  3961.171165  \n",
       "20     20  3956.860751  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist['rmse'] = hist['mse']**(1/2)\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d751d",
   "metadata": {},
   "source": [
    "**Only 20 epochs now, that's not so much. Impossible to train a neural network with only 20 iterations, tweaking some variables and monitoring another function instead of 'mse' would probably help here, but unfortunately time is limited. Maybe one day I'll optimize this neural network, but for now I'll call it a day.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132eae95",
   "metadata": {},
   "source": [
    "\n",
    "Please note that while making this project by myself, I sometimes used (parts) of lines of code from other sources. I do not own these code snippets and I would hereby like to list my code and learning sources:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d0797",
   "metadata": {},
   "source": [
    "-Hands-On machine learning with Scikil-Learn, Keras & TensorFlow book and pdf version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbb554",
   "metadata": {},
   "source": [
    "-Official wiki pages from all libraries used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f4b7fe",
   "metadata": {},
   "source": [
    "-Stackoverflow.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547d616",
   "metadata": {},
   "source": [
    "-Youtube.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
